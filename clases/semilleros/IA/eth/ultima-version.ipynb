{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71361,"databundleVersionId":7917425,"sourceType":"competition"}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Instructions for submission\n\n# 1. Rename this file to groupXX_PPGHR.ipynb where XX is your group number as visible in the Google spreadsheet\n# 2. State the team members (e-mail, legi):\n# example@student.ethz.ch, XX-YYY-ZZZ\n# TO BE FILLED\n# TO BE FILLED\n# 3. Kaggle team name: TO BE FILLED\n# 4. Upload this file in a zipped folder together with your final predictions to the provided Polybox link. See the Submission section in the PDF for more details.","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2024-03-24T21:14:29.055011Z","iopub.execute_input":"2024-03-24T21:14:29.055483Z","iopub.status.idle":"2024-03-24T21:14:29.091576Z","shell.execute_reply.started":"2024-03-24T21:14:29.055448Z","shell.execute_reply":"2024-03-24T21:14:29.089214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport matplotlib.dates as mdates\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport scipy as sp\nfrom scipy.signal import find_peaks, peak_prominences, savgol_filter\nfrom scipy.signal import butter, sosfilt\n","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2024-03-24T21:14:29.093749Z","iopub.execute_input":"2024-03-24T21:14:29.094902Z","iopub.status.idle":"2024-03-24T21:14:31.650930Z","shell.execute_reply.started":"2024-03-24T21:14:29.094856Z","shell.execute_reply":"2024-03-24T21:14:31.649792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sampling_rate = 128  # Hz\n\n# Load data item containing the PPG, HR, and IMU signals from all phases\ndata = np.load('/kaggle/input/24-exercise1/mhealth24_data_public.npy', allow_pickle=True).item() # now it is a dict\n#print(data)\nprint('Keys for data:', data.keys())\n\n# Example to extract the data from phase 0\nphase0_data = data['phase 0']\nprint('Keys for phase 0:', phase0_data.keys())\n\n# Get the individual signals from phase 0\nppg_phase0 = phase0_data['PPG wrist']\nref_hr_phase0 = phase0_data['ground truth HR']  # only available for phase 0, 2, and 4 (training data)\nIMU_X_phase0 = phase0_data['IMU X wrist']\nIMU_Y_phase0 = phase0_data['IMU Y wrist']\nIMU_Z_phase0 = phase0_data['IMU Z wrist']","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2024-03-24T21:14:31.652253Z","iopub.execute_input":"2024-03-24T21:14:31.652762Z","iopub.status.idle":"2024-03-24T21:14:32.326963Z","shell.execute_reply.started":"2024-03-24T21:14:31.652731Z","shell.execute_reply":"2024-03-24T21:14:32.325602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sig = data[\"phase 2\"][\"PPG head\"]\nspectrum = np.fft.fft(sig)\nfreq = np.fft.fftfreq(len(sig))\nplt.plot(freq, abs(sig))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:14:32.329607Z","iopub.execute_input":"2024-03-24T21:14:32.329942Z","iopub.status.idle":"2024-03-24T21:14:33.055253Z","shell.execute_reply.started":"2024-03-24T21:14:32.329915Z","shell.execute_reply":"2024-03-24T21:14:33.053780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Windows Configurations\nwinSize = 8*sampling_rate # Ground truth BPM provided in 8 second windows\nwinShift = 3*sampling_rate # Successive ground truth windows overlap by 3 seconds\n\n# CHOOSE WINDOW IN FILE\neval_window_idx = 3\n\noffset = eval_window_idx*winShift\n\nwindow_start = offset\nwindow_end = winSize+offset\noffset += winShift\n\n#print(len(sig),len(IMU_X_phase0_filtered_smooth), len(IMU_Y_phase0_filtered_smooth), len(IMU_Z_phase0_filtered_smooth))\n\nprint(f\"Win start,end: {window_start}, {window_end}\")\nppg_window = sig[window_start:window_end]\n\naccx_window = IMU_X_phase0[window_start:window_end]\naccy_window = IMU_Y_phase0[window_start:window_end]\naccz_window = IMU_Z_phase0[window_start:window_end]\nprint(len(ppg_window), len(accx_window), len(accy_window), len(accz_window))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:14:33.057146Z","iopub.execute_input":"2024-03-24T21:14:33.057943Z","iopub.status.idle":"2024-03-24T21:14:33.069563Z","shell.execute_reply.started":"2024-03-24T21:14:33.057900Z","shell.execute_reply":"2024-03-24T21:14:33.068577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to plot any signal with time on the x-axis\ndef plot_signal(signal, title, ylabel, plot_window_start, sampling_rate=128, peaks = []):\n    x = np.linspace(plot_window_start, plot_window_start+(len(signal) / sampling_rate), len(signal))\n    t = pd.to_datetime(x, unit='s')\n\n    fig, ax = plt.subplots(figsize=(15,5))\n    ax.plot(t, signal)\n    \n    if len(peaks)>0:\n        for p in peaks:\n            plt.axvline(p, alpha = 0.2)\n            \n    ax.set_title(title)\n    ax.set_xlabel('Time [min:sec]')\n    ax.set_ylabel(ylabel)\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%M:%S'))\n    \n    plt.show()\n    \ndef plot_signal_wrapper(signal, title,ylabel, peaks = []):\n    plot_window_start = 3  # in seconds\n    plot_window_end = 30  # in seconds\n    \n    #convert peaks for plotting\n    if len(peaks)>0:\n        peaks = [p/sampling_rate for p in peaks]\n        peaks = [p for p in peaks if plot_window_start<= p <= plot_window_end]\n        peaks = pd.to_datetime(peaks, unit='s')\n    \n    #plot raw\n    plot_signal(signal[plot_window_start*sampling_rate:plot_window_end*sampling_rate], title,ylabel, peaks = peaks, plot_window_start = plot_window_start)\n\n# If you want to be able to interactively look at your plotted data (e.g., zooming in or out),\n# uncomment the line with \"%matplotlib widget\" below\n# Careful: This does not work on Kaggle, but requires that you run the Jupyter Notebook locally on your computer\n# If you have an interactive plot and you want to go back to the non-interactive plot, comment the line with \n# \"%matplotlib widget\" out and restart your kernel\n# If you accidently run this script on Kaggle when \"%matplotlib widget\" is not commented out and you receive an error afterwards that your plot cannot be plotted, comment \"%matplotlib widget\" out and restart the kernel via \"Run << Factory reset\"\n\n# %matplotlib widget\n\n# Example plot of a 10-second window of the PPG signal\n#plot_window_start = 20  # in seconds\n#plot_window_end = 35  # in seconds\n#plot_signal(sig_filtered[plot_window_start*sampling_rate:plot_window_end*sampling_rate], 'PPG wrist', 'Amplitude', add_peaks = True)","metadata":{"pycharm":{"is_executing":true,"name":"#%%\n"},"execution":{"iopub.status.busy":"2024-03-24T21:14:33.072980Z","iopub.execute_input":"2024-03-24T21:14:33.073627Z","iopub.status.idle":"2024-03-24T21:14:33.090397Z","shell.execute_reply.started":"2024-03-24T21:14:33.073591Z","shell.execute_reply":"2024-03-24T21:14:33.088904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def butter_bandpass(lowcut, highcut, fs, order):\n    nyq = 0.5 * fs\n    low = lowcut / nyq\n    high = highcut / nyq\n    sos = butter(order, [low, high], btype=\"band\",output=\"sos\")\n    return sos\ndef butter_bandpass_filt(data, lowcut, highcut,fs, order):\n    sos = butter_bandpass(lowcut, highcut, fs,order)\n    y = sosfilt(sos, data)\n    return y\n\ndef BandpassFilter(signal, fs):\n    lo, hi = 40/60, 180/60\n    b, a = sp.signal.butter(3, (lo, hi), btype='bandpass', fs=fs)\n    return sp.signal.filtfilt(b, a, signal)\n\ndef FreqTransform(x, freqs, low_freqs, fft_len):\n    norm_x = (x - np.mean(x))/(max(x)-min(x))\n    fft_x = np.fft.rfft(norm_x, fft_len)\n    mag_freq_x = np.abs(fft_x)[low_freqs]\n    return mag_freq_x, fft_x\n\ndef CalcConfidence(chosen_freq, freqs, fft_ppg):\n    win = (40/60.0)\n    win_freqs = (freqs >= chosen_freq - win) & (freqs <= chosen_freq + win)\n    abs_fft_ppg = np.abs(fft_ppg)\n    conf_val = np.sum(abs_fft_ppg[win_freqs])/np.sum(abs_fft_ppg)\n\n    return conf_val\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:14:33.092339Z","iopub.execute_input":"2024-03-24T21:14:33.093179Z","iopub.status.idle":"2024-03-24T21:14:33.108528Z","shell.execute_reply.started":"2024-03-24T21:14:33.093136Z","shell.execute_reply":"2024-03-24T21:14:33.107201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_hr_2(sig, accx, accy, accz, title=\"\", ylabel=\"\", sampling_rate=128, plot=False, just_estimate=False, verbose=False):    \n    if not just_estimate:\n        hr_estimate = get_hr_2(sig, accx, accy, accz, title=title, ylabel=ylabel, sampling_rate=sampling_rate, plot=plot, just_estimate=True, verbose=verbose)\n       \n    #plot raw\n    if plot:\n        plot_signal_wrapper(sig, title,ylabel)\n \n    #filter\n    \n\n \n    #sig_filtered = butter_bandpass_filt(sig, 40/60, 180/60, sampling_rate, 3)\n    ppg_bandpass = BandpassFilter(sig, fs=128)\n    accx_bandpass = accx#BandpassFilter(accx, fs=sampling_rate)\n    accy_bandpass = accy#BandpassFilter(accy, fs=sampling_rate)\n    accz_bandpass = accz#BandpassFilter(accz, fs=sampling_rate)\n    \n    # Aggregate accelerometer data into single signal\n    accy_centered = accy_bandpass - np.mean(accy_bandpass)  # Centering accy_bandpass\n    acc_mag_unfiltered = np.sqrt(accx_bandpass**2 + accy_centered**2 + accz_bandpass**2)\n    acc_mag = BandpassFilter(acc_mag_unfiltered, fs=sampling_rate)\n    peaks = find_peaks(ppg_bandpass, height = 10, distance=35)[0]\n    \n    if verbose:\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,4))\n        ax1.title.set_text('Signal with Time Domain FindPeaks()')\n        ax1.plot(sig_filtered)\n        ax1.plot(peaks, sig_filtered[peaks], \"x\")\n\n        ax2.title.set_text('Aggregated Accelerometer Data')\n        ax2.plot(acc_mag, color=\"purple\")\n        plt.show()\n    # Use FFT length larger than the input signal size for higher spectral resolution.\n    fft_len=len(sig_filtered)*4\n \n    # Create an array of frequency bins\n    freqs = np.fft.rfftfreq(fft_len, 1 / sampling_rate) # bins of width 0.12207031\n \n    # The frequencies between 40 BPM and 180 BPM Hz\n    low_freqs = (freqs >= (40/60)) & (freqs <= (180/60))\n    \n    mag_freq_ppg, fft_ppg = FreqTransform(sig_filtered, freqs, low_freqs, fft_len)\n    \n    mag_freq_acc, fft_acc = FreqTransform(acc_mag, freqs, low_freqs, fft_len)\n    \n    peaks_ppg = find_peaks(mag_freq_ppg, height=30, distance=1)[0]\n    peaks_acc = find_peaks(mag_freq_acc, height=30, distance=1)[0]\n    \n    # Sort peaks in order of peak magnitude\n    sorted_freq_peaks_ppg = sorted(peaks_ppg, key=lambda i:mag_freq_ppg[i], reverse=True)\n    sorted_freq_peaks_acc = sorted(peaks_acc, key=lambda i:mag_freq_acc[i], reverse=True)\n    \n    # Use the frequency peak with the highest magnitude, unless the peak is also present in the accelerometer peaks.\n    use_peak = sorted_freq_peaks_ppg[0]\n    for i in range(len(sorted_freq_peaks_ppg)):\n        # Check nearest two peaks also\n        cond1 = sorted_freq_peaks_ppg[i] in sorted_freq_peaks_acc\n        cond2 = sorted_freq_peaks_ppg[i]-1 in sorted_freq_peaks_acc\n        cond3 = sorted_freq_peaks_ppg[i]+1 in sorted_freq_peaks_acc\n        \n        if cond1 or cond2 or cond3:\n            continue\n        else:\n            use_peak = sorted_freq_peaks_ppg[i]\n            break  \n            \n\n \n        \n    chosen_freq = freqs[low_freqs][use_peak]\n    prediction = chosen_freq * 60\n    confidence = CalcConfidence(chosen_freq, freqs, fft_ppg)\n    if plot:\n        plot_signal_wrapper(ppg_bandpass, title,ylabel, peaks = peaks)\n    if verbose:\n        plt.title(\"PPG Frequency Magnitude\")\n        plt.plot(mag_freq_ppg)\n        plt.plot(peaks_ppg, mag_freq_ppg[peaks_ppg], \"x\")\n        plt.show()\n        \n        plt.title(\"ACC Frequency Magnitude\")\n        plt.plot(mag_freq_acc, color=\"purple\")\n        plt.plot(peaks_acc, mag_freq_acc[peaks_acc], \"x\")\n        plt.show()\n        \n        print(\"PPG Freq Peaks: \", peaks_ppg)\n        print(\"ACC Freq Peaks: \", peaks_acc)\n        \n        print(\"PPG Freq Peaks Sorted: \", sorted_freq_peaks_ppg)\n        print(\"ACC Freq Peaks Sorted: \", sorted_freq_peaks_acc)\n        print(\"Use peak: \", use_peak)\n        print(f\"Predicted BPM: {prediction}, {chosen_freq} (Hz), Confidence: {confidence}\")        \n        \n    \n    # Sum frequency spectrum near pulse rate estimate and divide by sum of entire spectrum\n\n    #prediction, confidence = 60, 0.9  # Placeholder values\n    return prediction, confidence         \n        \n    #find peaks\n    #from scipy.signal import find_peaks, peak_prominences\n    #peaks = find_peaks(sig_filtered, distance = 3, prominence = 10)[0]\n    #prominences = peak_prominences(sig_filtered, peaks)[0]\n    #min_prominence = np.quantile(prominences, 0.2)\n    \n    #if not just_estimate:\n    #    #make min_prominence dependent on heartrate\n    #    hr_factor = (hr_estimate-40)/(180-40)\n    #    min_prominence = np.quantile(prominences, 0.15-0.1*hr_factor)\n \n    ##recompute peaks\n    #peaks = find_peaks(sig_filtered, prominence = min_prominence, distance=sampling_rate/(180/60))[0]\n    \n            \n    ##plot with peaks\n    #if plot:\n    #    plot_signal_wrapper(sig_filtered, title,ylabel, peaks = peaks)\n    \n    ## extract median time between peaks\n    #time_between_peaks = []\n    #for i in range(1, len(peaks)):\n    #    time_between_peaks.append((peaks[i]-peaks[i-1])/sampling_rate)\n    ##print(time_between_peaks[:10])\n    \n    \n    ## zscore normalize\n    #outlier_low = np.mean(time_between_peaks) - 1.2 * np.std(time_between_peaks)\n    #outlier_high = np.mean(time_between_peaks) + 1.2 * np.std(time_between_peaks)\n    #len_before = len(time_between_peaks)\n    #time_between_peaks = [p for p in time_between_peaks if outlier_low <= p <= outlier_high]   \n    #print(f\"removed {len_before-len(time_between_peaks)} outliers out of {len_before} datapoints\")\n    \n    #return 60/np.mean(time_between_peaks)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:31:17.018697Z","iopub.execute_input":"2024-03-24T21:31:17.019161Z","iopub.status.idle":"2024-03-24T21:31:17.047236Z","shell.execute_reply.started":"2024-03-24T21:31:17.019125Z","shell.execute_reply":"2024-03-24T21:31:17.045864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#before hr\n\ndef get_hr_1(sig,title=\"\",ylabel=\"\", sampling_rate = 128, plot = False, just_estimate = False):\n    \n    \n    if not just_estimate:\n        hr_estimate = get_hr_1(sig,title=\"\",ylabel=\"\", sampling_rate = 128, plot = False, just_estimate = True)\n    \n    \n    #plot raw\n    if plot:\n        plot_signal_wrapper(sig, title,ylabel)\n\n    #filter\n\n    sig_filtered = butter_bandpass_filt(sig, 40/60, 180/60, sampling_rate, 3)\n    \n    \n    #find peaks\n    from scipy.signal import find_peaks, peak_prominences\n    peaks = find_peaks(sig_filtered, distance = 3, prominence = 10)[0]\n    prominences = peak_prominences(sig_filtered, peaks)[0]\n    min_prominence = np.quantile(prominences, 0.2)\n    \n    if not just_estimate:\n        #make min_prominence dependent on heartrate\n        hr_factor = (hr_estimate-40)/(180-40)\n        min_prominence = np.quantile(prominences, 0.15-0.1*hr_factor)\n\n    #recompute peaks\n    peaks = find_peaks(sig_filtered, prominence = min_prominence, distance=sampling_rate/(180/60))[0]\n    \n            \n    #plot with peaks\n    if plot:\n        plot_signal_wrapper(sig_filtered, title,ylabel, peaks = peaks)\n    \n    # extract median time between peaks\n    time_between_peaks = []\n    for i in range(1, len(peaks)):\n        time_between_peaks.append((peaks[i]-peaks[i-1])/sampling_rate)\n    #print(time_between_peaks[:10])\n    \n    \n    # zscore normalize\n    outlier_low = np.mean(time_between_peaks) - 1.2 * np.std(time_between_peaks)\n    outlier_high = np.mean(time_between_peaks) + 1.2 * np.std(time_between_peaks)\n    len_before = len(time_between_peaks)\n    time_between_peaks = [p for p in time_between_peaks if outlier_low <= p <= outlier_high]   \n    #print(f\"removed {len_before-len(time_between_peaks)} outliers out of {len_before} datapoints\")\n    \n    return 60/np.mean(time_between_peaks)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:28:03.498839Z","iopub.execute_input":"2024-03-24T21:28:03.499215Z","iopub.status.idle":"2024-03-24T21:28:03.514101Z","shell.execute_reply.started":"2024-03-24T21:28:03.499186Z","shell.execute_reply":"2024-03-24T21:28:03.512671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accx_window_filter=BandpassFilter(accx_window, fs=sampling_rate)\naccy_window_filter=BandpassFilter(accy_window, fs=sampling_rate)\naccz_window_filter=BandpassFilter(accz_window, fs=sampling_rate)\nsig_filtered = butter_bandpass_filt(sig, 40/60, 180/60, sampling_rate, 3)\n\nhr = get_hr_2(sig,accx_window,accy_window,accz_window, plot = True)\n#hr = get_hr_2(sig_filtered,accx_window_filter,accy_window_filter,accz_window_filter, plot = True)\n\npred = get_hr_1(sig,title = f\"phase {phase}\", ylabel=\"signal\", plot = True)\n\n\nprint(hr)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:31:22.730040Z","iopub.execute_input":"2024-03-24T21:31:22.730533Z","iopub.status.idle":"2024-03-24T21:31:25.264548Z","shell.execute_reply.started":"2024-03-24T21:31:22.730494Z","shell.execute_reply":"2024-03-24T21:31:25.263060Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Define Kalman filter parameters\n#Q = 1e-5  # Process noise covariance\n#R = 0.1  # Measurement noise covariance\n#x_initial = 0  # Initial state\n#P_initial = 1  # Initial covariance\n\n## Define the Kalman filter function\n#def kalman_filter(data, Q, R, x_initial, P_initial):\n#    n = len(data)\n#    x_hat = np.zeros(n)  # Estimated state\n#    P = np.zeros(n)  # Covariance\n#    K = np.zeros(n)  # Kalman gain\n\n#    x_hat_minus = x_initial\n#    P_minus = P_initial\n\n#    for i in range(n):\n#        # Prediction update\n#        x_hat_minus = x_hat[i-1]\n#        P_minus = P[i-1] + Q\n\n#        # Measurement update\n#        K[i] = P_minus / (P_minus + R)\n#        x_hat[i] = x_hat_minus + K[i] * (data[i] - x_hat_minus)\n#        P[i] = (1 - K[i]) * P_minus\n\n#    return x_hat\n\n## Apply the Kalman filter to IMU data\n#IMU_X_phase0_filtered = kalman_filter(IMU_X_phase0, Q, R, x_initial, P_initial)\n#IMU_Y_phase0_filtered = kalman_filter(IMU_Y_phase0, Q, R, x_initial, P_initial)\n#IMU_Z_phase0_filtered = kalman_filter(IMU_Z_phase0, Q, R, x_initial, P_initial)\n\n## Apply additional noise reduction using Savitzky-Golay filter\n#window_length = 21\n#polyorder = 3\n#IMU_X_phase0_filtered_smooth = savgol_filter(IMU_X_phase0_filtered, window_length, polyorder)\n#IMU_Y_phase0_filtered_smooth = savgol_filter(IMU_Y_phase0_filtered, window_length, polyorder)\n#IMU_Z_phase0_filtered_smooth = savgol_filter(IMU_Z_phase0_filtered, window_length, polyorder)\n#print(IMU_X_phase0_filtered_smooth)\n## Plotting\n#plt.figure(figsize=(12, 6))\n\n#plt.subplot(3, 1, 1)\n#plt.plot(IMU_X_phase0_filtered_smooth, label='IMU X (filtered)')\n#plt.title('Filtered IMU X Data - Phase 0')\n#plt.xlabel('Sample')\n#plt.ylabel('Acceleration')\n#plt.legend()\n#plt.grid(True)\n\n#plt.subplot(3, 1, 2)\n#plt.plot(IMU_Y_phase0_filtered_smooth, label='IMU Y (filtered)')\n#plt.title('Filtered IMU Y Data - Phase 0')\n#plt.xlabel('Sample')\n#plt.ylabel('Acceleration')\n#plt.legend()\n#plt.grid(True)\n\n#plt.subplot(3, 1, 3)\n#plt.plot(IMU_Z_phase0_filtered_smooth, label='IMU Z (filtered)')\n#plt.title('Filtered IMU Z Data - Phase 0')\n#plt.xlabel('Sample')\n#plt.ylabel('Acceleration')\n#plt.legend()\n#plt.grid(True)\n\n#plt.tight_layout()\n#plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:14:33.737952Z","iopub.status.idle":"2024-03-24T21:14:33.738430Z","shell.execute_reply.started":"2024-03-24T21:14:33.738167Z","shell.execute_reply":"2024-03-24T21:14:33.738184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to print the mean and median absolute error between your predicted HR and the reference HR\n# With this function, you can evaluate the resulting score that you would obtain on the public dataset\n# with your predicted HR values on Kaggle\ndef print_score(pred_hr, ref_hr):\n    err = np.abs(np.asarray(pred_hr) - np.asarray(ref_hr))\n    print(\"Mean error: {:4.3f}, Median error {:4.3f}\".format(np.mean(err), np.median(err)))\n    print(\"Resulting score {:4.3f}\".format(0.5 * np.mean(err) + 0.5 * np.median(err)))\n    return 0.5 * np.mean(err) + 0.5 * np.median(err)\n\n# Example on how to use the print_score function with randomly generated HR values as the predictions\npred_hr_phase0 = list(np.random.randint(40, 180, len(ref_hr_phase0)))\nprint_score(pred_hr_phase0, ref_hr_phase0)","metadata":{"pycharm":{"is_executing":true,"name":"#%%\n"},"execution":{"iopub.status.busy":"2024-03-24T21:32:20.835673Z","iopub.execute_input":"2024-03-24T21:32:20.836165Z","iopub.status.idle":"2024-03-24T21:32:20.853696Z","shell.execute_reply.started":"2024-03-24T21:32:20.836125Z","shell.execute_reply":"2024-03-24T21:32:20.852142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Windows Configurations\nwinSize = 8*sampling_rate # Ground truth BPM provided in 8 second windows\nwinShift = 3*sampling_rate # Successive ground truth windows overlap by 3 seconds\n\n# CHOOSE WINDOW IN FILE\neval_window_idx = 3\n\noffset = eval_window_idx*winShift\n\nwindow_start = offset\nwindow_end = winSize+offset\noffset += winShift\n\n#print(len(sig),len(IMU_X_phase0_filtered_smooth), len(IMU_Y_phase0_filtered_smooth), len(IMU_Z_phase0_filtered_smooth))\n\nprint(f\"Win start,end: {window_start}, {window_end}\")\nppg_window = sig[window_start:window_end]\n\naccx_window = IMU_X_phase0[window_start:window_end]\naccy_window = IMU_Y_phase0[window_start:window_end]\naccz_window = IMU_Z_phase0[window_start:window_end]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:17:52.044238Z","iopub.execute_input":"2024-03-24T21:17:52.044654Z","iopub.status.idle":"2024-03-24T21:17:52.060533Z","shell.execute_reply.started":"2024-03-24T21:17:52.044623Z","shell.execute_reply":"2024-03-24T21:17:52.058987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def chunker(seq, size):\n    return [seq[pos:pos + size] for pos in range(0, len(seq), size)]\n    \ndat = {\n    0:data[\"phase 0\"][\"PPG wrist\"],\n    2:data[\"phase 2\"][\"PPG head\"],\n    4:data[\"phase 4\"][\"PPG head\"]\n}\nscores = []\nfor phase in [0,2,4]:\n    \n    sig = dat[phase]\n    true_hr = data[f\"phase {phase}\"]['ground truth HR']\n    \n    \n    plot_this = False\n    collected_preds = []\n    \n    c = 0\n    ccritical = 139\n    #not\n    \"\"\"\n    for section in chunker(sig, 30*sampling_rate):   \n        \n        if c==ccritical:\n            plot_this = True\n        print(len(section), len(chunker(sig, 30*sampling_rate)))\n        pred = get_hr_1(section,title = f\"not pau phase {phase}\", ylabel=\"signal\", plot = plot_this)\n        #pred_pau, confidence = get_hr_2(section,accx_window,accy_window,accz_window, plot = True)\n        if plot_this:\n            print(\"pred\",pred)\n        if c==ccritical:\n            plot_this = False\n        collected_preds.append(pred)\n        c+=1\n    \"\"\"\n    #this\n    for section in range(len(chunker(sig, 30*sampling_rate))):   \n        offset = abs(section*winShift)\n        window_start = offset\n        window_end = winSize+offset\n        offset += winShift\n        print(f\"Win start,end: {window_start}, {window_end}\")\n        ppg_window = sig[window_start:window_end]\n\n        accx_window = IMU_X_phase0[window_start:window_end]\n        accy_window = IMU_Y_phase0[window_start:window_end]\n        accz_window = IMU_Z_phase0[window_start:window_end]\n        if c==ccritical:\n            plot_this = True\n        #print(len(section))\n        #pred = get_hr_1(section,title = f\"not pau phase {phase}\", ylabel=\"signal\", plot = plot_this)\n        pau, confidence = get_hr_2(ppg_window,accx_window,accy_window,accz_window, plot = True)\n        if plot_this:\n            print(\"pred\",pred)\n        if c==ccritical:\n            plot_this = False\n        collected_preds.append(pred)\n        c+=1\n        \n    scores.append(print_score(collected_preds, true_hr))\n    \n    print(f\"\\ni\\t\\tpredicted\\ttrue\\t\\tdiff\")\n    diffs = []\n    for i in range(len(collected_preds)):\n        diff = round(collected_preds[i]-true_hr[i],1)\n        diffs.append(diff)\n        print(f\"{i}\\t\\t{round(collected_preds[i],1)}\\t\\t{round(true_hr[i],1)}\\t\\t{diff}\")\n        break\n    print(f\"avg diff: {np.mean(diffs)}\")\nprint(np.mean(scores))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:49:35.413196Z","iopub.execute_input":"2024-03-24T21:49:35.413712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[\"phase 5\"].keys()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:14:33.746774Z","iopub.status.idle":"2024-03-24T21:14:33.747174Z","shell.execute_reply.started":"2024-03-24T21:14:33.746986Z","shell.execute_reply":"2024-03-24T21:14:33.747003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For each phase, you should now have obtained a list of predicted HR values\n# Below, we give an example of how you can produce the submission.csv file from your predicted HR values\n# To demonstrate the format of the submission.csv file, we provide an example with randomly generated HR values\n# For phase 0, 1, 2, and 3 you should each obtain 396 HR values\n# For phase 4 and 5 you should each obtain 57 HR values\n# IMPORTANT: You have to replace the following predicted HR values with your predicted HR values!\n\ncollected_preds = []\ndat = {\n    0:data[\"phase 0\"][\"PPG wrist\"],\n    1:data[\"phase 1\"][\"PPG head\"],\n    2:data[\"phase 2\"][\"PPG head\"],\n    3:data[\"phase 3\"][\"PPG wrist\"],\n    4:data[\"phase 4\"][\"PPG head\"],\n    5:data[\"phase 5\"][\"PPG head\"]\n}\nfor phase in [0,1,2,3,4,5]:\n\n    \n    sig = dat[phase]    \n    collected_preds_per_phase = []\n\n    for section in chunker(sig, 30*sampling_rate):        \n        pred = get_hr_1(section,title = f\"phase {phase}\", ylabel=\"signal\")\n        collected_preds_per_phase.append(pred)\n    collected_preds.append(collected_preds_per_phase)\n\npred_hr_phase0 = collected_preds[0]\npred_hr_phase1 = collected_preds[1]\npred_hr_phase2 = collected_preds[2]\npred_hr_phase3 = collected_preds[3]\npred_hr_phase4 = collected_preds[4]\npred_hr_phase5 = collected_preds[5]\n\n# You can keep the below code unchanged to produce the submission.csv file\npred_hr_phases = [pred_hr_phase0, pred_hr_phase1, pred_hr_phase2,\n                  pred_hr_phase3, pred_hr_phase4, pred_hr_phase5]\nids = []\npred_hr_flattened = []\n\n\nfor phase_counter in range(len(pred_hr_phases)):\n    for hr_counter in range(len(pred_hr_phases[phase_counter])):\n        pred_hr_flattened.append(pred_hr_phases[phase_counter][hr_counter])\n        ids.append(f'phase{phase_counter}_{hr_counter}')\n\n# If you use Kaggle, on the right side in tab \"Output\", you should now see a file called \"submission.csv\" after pressing \"refresh\"\n# Download the file and submit it to the competition on Kaggle to obtain a score on the leaderboard for your team\ndf = pd.DataFrame({'Id': ids, 'Predicted': pred_hr_flattened})\ndf.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"pycharm":{"name":"#%%\n"},"execution":{"iopub.status.busy":"2024-03-24T21:14:33.748624Z","iopub.status.idle":"2024-03-24T21:14:33.748987Z","shell.execute_reply.started":"2024-03-24T21:14:33.748810Z","shell.execute_reply":"2024-03-24T21:14:33.748825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def write_new_csv():\n#    collected_preds = []\n#    for phase in [0,1,2,3,4,5]:\n#        data_phase = data[f'phase {phase}']\n#        ppg_phase0 = data_phase['PPG wrist']\n#        ref_hr_phase0 = data_phase['ground truth HR']  # only available for phase 0, 2, and 4 (training data)\n#        IMU_X_phase0 = data_phase['IMU X wrist']\n#        IMU_Y_phase0 = data_phase['IMU Y wrist']\n#        IMU_Z_phase0 = data_phase['IMU Z wrist']\n        \n#    df = pd.DataFrame({'Id': ids, 'Predicted': pred_hr_flattened})\n#    df.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T21:14:33.750502Z","iopub.status.idle":"2024-03-24T21:14:33.750893Z","shell.execute_reply.started":"2024-03-24T21:14:33.750707Z","shell.execute_reply":"2024-03-24T21:14:33.750723Z"},"trusted":true},"execution_count":null,"outputs":[]}]}